"""
DSTG-V2 Hybrid Graph Model
æ··åˆå›¾æ¶æ„ï¼šèåˆç›¸å…³æ€§å›¾ + è¯­ä¹‰å›¾

æ ¸å¿ƒåˆ›æ–°:
1. Correlation Graph: åŸºäºç»Ÿè®¡ç›¸å…³æ€§ï¼ˆV13ï¼‰
2. Semantic Graph: åŸºäºé€šé“åµŒå…¥ + æ³¨æ„åŠ›ï¼ˆV24ï¼‰
3. Adaptive Fusion: è‡ªé€‚åº”èåˆä¸¤ç§å›¾
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np


class CorrelationGraphConstructor(nn.Module):
    """
    ç›¸å…³æ€§å›¾æ„å»ºå™¨ï¼ˆV13 é£æ ¼ï¼‰
    åŸºäºç»Ÿè®¡ç›¸å…³æ€§ + å­¦ä¹ è¾¹æƒé‡
    """
    def __init__(self, num_channels=22, feature_dim=448, dropout=0.1):
        super().__init__()
        self.num_channels = num_channels
        self.feature_dim = feature_dim
        
        # è¾¹æƒé‡å­¦ä¹ ç½‘ç»œ
        self.edge_weight_net = nn.Sequential(
            nn.Linear(feature_dim * 2, 64),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
        
        print("âœ… ç›¸å…³æ€§å›¾æ„å»ºå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def compute_correlation_matrix(self, x):
        """
        å‘é‡åŒ–è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        x: (batch, num_channels, feature_dim)
        """
        # æ ‡å‡†åŒ–
        x_mean = x.mean(dim=-1, keepdim=True)
        x_centered = x - x_mean
        x_std = x_centered.std(dim=-1, keepdim=True) + 1e-8
        x_norm = x_centered / x_std
        
        # ç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = torch.bmm(x_norm, x_norm.transpose(1, 2)) / x.size(-1)
        
        return torch.abs(corr_matrix)
    
    def learn_edge_weights(self, x):
        """
        å­¦ä¹ è¾¹æƒé‡ï¼ˆå‘é‡åŒ–ï¼‰
        x: (batch, num_channels, feature_dim)
        """
        batch_size, num_channels, feature_dim = x.size()
        
        # æ‰©å±•ä¸ºæ‰€æœ‰é€šé“å¯¹
        x_i = x.unsqueeze(2).expand(-1, -1, num_channels, -1)
        x_j = x.unsqueeze(1).expand(-1, num_channels, -1, -1)
        
        # æ‹¼æ¥: (batch, num_channels, num_channels, feature_dim*2)
        edge_features = torch.cat([x_i, x_j], dim=-1)
        
        # å­¦ä¹ æƒé‡: (batch, num_channels, num_channels)
        weights = self.edge_weight_net(edge_features).squeeze(-1)
        
        return weights
    
    def forward(self, x):
        """
        x: (batch, num_channels, feature_dim)
        Returns: (batch, num_channels, num_channels)
        """
        batch_size = x.size(0)
        
        # 1. è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = self.compute_correlation_matrix(x)
        
        # 2. å­¦ä¹ è¾¹æƒé‡
        edge_weights = self.learn_edge_weights(x)
        
        # 3. åŠ æƒç›¸å…³æ€§
        adj_matrix = corr_matrix * edge_weights
        
        # 4. æ·»åŠ è‡ªè¿æ¥
        eye = torch.eye(self.num_channels, device=x.device).unsqueeze(0).expand(batch_size, -1, -1)
        adj_matrix = adj_matrix + eye
        
        return adj_matrix


class SemanticGraphConstructor(nn.Module):
    """
    è¯­ä¹‰å›¾æ„å»ºå™¨ï¼ˆV24 é£æ ¼ï¼‰
    åŸºäºé€šé“åµŒå…¥ + æ³¨æ„åŠ›æœºåˆ¶
    """
    def __init__(self, num_channels=22, feature_dim=448, hidden_dim=64, dropout=0.3):
        super().__init__()
        self.num_channels = num_channels
        self.feature_dim = feature_dim
        
        # æ¯ä¸ªé€šé“çš„å¯å­¦ä¹ åµŒå…¥ï¼ˆå…³é”®åˆ›æ–°ï¼ï¼‰
        self.channel_embedding = nn.Parameter(
            torch.randn(num_channels, hidden_dim) * 0.01
        )
        
        # è¾¹æƒé‡è®¡ç®—ç½‘ç»œ
        edge_input_dim = hidden_dim * 2 + feature_dim * 2
        
        self.edge_network = nn.Sequential(
            nn.Linear(edge_input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
        
        # ç¨€ç–åŒ–é˜ˆå€¼ï¼ˆå¯å­¦ä¹ ï¼‰
        self.sparsity_threshold = nn.Parameter(torch.tensor(0.3))
        
        print(f"âœ… è¯­ä¹‰å›¾æ„å»ºå™¨åˆå§‹åŒ–å®Œæˆ (åµŒå…¥ç»´åº¦: {hidden_dim})")
    
    def forward(self, x):
        """
        x: (batch, num_channels, feature_dim)
        Returns: (batch, num_channels, num_channels)
        """
        batch_size, num_channels, feature_dim = x.size()
        
        # æ‰©å±•é€šé“åµŒå…¥åˆ° batch
        channel_emb = self.channel_embedding.unsqueeze(0).expand(batch_size, -1, -1)
        
        # æ„å»ºé‚»æ¥çŸ©é˜µ
        adj = torch.zeros(batch_size, num_channels, num_channels).to(x.device)
        
        # è®¡ç®—æ‰€æœ‰è¾¹çš„æƒé‡
        for i in range(num_channels):
            for j in range(i+1, num_channels):
                # æ‹¼æ¥: åµŒå…¥i + åµŒå…¥j + ç‰¹å¾i + ç‰¹å¾j
                edge_input = torch.cat([
                    channel_emb[:, i],
                    channel_emb[:, j],
                    x[:, i],
                    x[:, j]
                ], dim=1)
                
                # è®¡ç®—è¾¹æƒé‡
                weight = self.edge_network(edge_input).squeeze(1)
                
                adj[:, i, j] = weight
                adj[:, j, i] = weight  # å¯¹ç§°
        
        # ç¨€ç–åŒ–
        threshold = torch.sigmoid(self.sparsity_threshold)
        adj = torch.where(
            adj > threshold,
            adj,
            torch.zeros_like(adj)
        )
        
        # æ·»åŠ è‡ªè¿æ¥
        eye = torch.eye(num_channels).unsqueeze(0).expand(batch_size, -1, -1).to(x.device)
        adj = adj + eye
        
        return adj


class HybridGraphConstructor(nn.Module):
    """
    æ··åˆå›¾æ„å»ºå™¨ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼ï¼‰
    è‡ªé€‚åº”èåˆç›¸å…³æ€§å›¾ + è¯­ä¹‰å›¾
    
    åˆ›æ–°ç‚¹:
    1. èåˆç»Ÿè®¡ç›¸å…³æ€§ + å­¦ä¹ è¯­ä¹‰å…³ç³»
    2. è‡ªé€‚åº”å­¦ä¹ èåˆæƒé‡
    3. å……åˆ†åˆ©ç”¨ä¸¤ç§å›¾çš„ä¼˜åŠ¿
    """
    def __init__(self, num_channels=22, feature_dim=448, hidden_dim=64, 
                 fusion_mode='learned', fixed_alpha=0.6, dropout=0.1):
        super().__init__()
        self.num_channels = num_channels
        self.fusion_mode = fusion_mode
        
        print("="*70)
        print("ğŸ”¥ åˆå§‹åŒ–æ··åˆå›¾æ„å»ºå™¨ (Hybrid Graph Constructor)")
        print("="*70)
        
        # ç›¸å…³æ€§å›¾åˆ†æ”¯
        self.corr_graph = CorrelationGraphConstructor(
            num_channels=num_channels,
            feature_dim=feature_dim,
            dropout=dropout
        )
        
        # è¯­ä¹‰å›¾åˆ†æ”¯
        self.semantic_graph = SemanticGraphConstructor(
            num_channels=num_channels,
            feature_dim=feature_dim,
            hidden_dim=hidden_dim,
            dropout=dropout * 3  # è¯­ä¹‰å›¾ç”¨æ›´é«˜çš„ dropout
        )
        
        # èåˆç­–ç•¥
        if fusion_mode == 'fixed':
            # å›ºå®šæƒé‡èåˆ
            self.alpha = fixed_alpha
            print(f"âœ… èåˆæ¨¡å¼: å›ºå®šæƒé‡ (Î±={fixed_alpha:.2f})")
        elif fusion_mode == 'learned':
            # å­¦ä¹ èåˆæƒé‡ï¼ˆå…¨å±€ï¼‰
            self.alpha_param = nn.Parameter(torch.tensor(0.6))
            print("âœ… èåˆæ¨¡å¼: å­¦ä¹ å…¨å±€æƒé‡")
        elif fusion_mode == 'adaptive':
            # è‡ªé€‚åº”èåˆï¼ˆåŸºäºç‰¹å¾ï¼‰
            self.fusion_net = nn.Sequential(
                nn.Linear(feature_dim * num_channels, 128),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(128, 1),
                nn.Sigmoid()
            )
            print("âœ… èåˆæ¨¡å¼: è‡ªé€‚åº”èåˆç½‘ç»œ")
        else:
            raise ValueError(f"Unknown fusion_mode: {fusion_mode}")
        
        self.fusion_mode = fusion_mode
        
        print("="*70)
        print("âœ… æ··åˆå›¾æ„å»ºå™¨åˆå§‹åŒ–å®Œæˆï¼")
        print(f"   - ç›¸å…³æ€§å›¾: ç»Ÿè®¡ç›¸å…³æ€§ + å­¦ä¹ è¾¹æƒé‡")
        print(f"   - è¯­ä¹‰å›¾: é€šé“åµŒå…¥ + æ³¨æ„åŠ›æœºåˆ¶")
        print(f"   - èåˆç­–ç•¥: {fusion_mode}")
        print("="*70)
    
    def compute_fusion_weight(self, x):
        """
        è®¡ç®—èåˆæƒé‡ Î±
        Î± = 1: å®Œå…¨ä½¿ç”¨ç›¸å…³æ€§å›¾
        Î± = 0: å®Œå…¨ä½¿ç”¨è¯­ä¹‰å›¾
        """
        if self.fusion_mode == 'fixed':
            return self.alpha
        elif self.fusion_mode == 'learned':
            return torch.sigmoid(self.alpha_param)
        elif self.fusion_mode == 'adaptive':
            # åŸºäºç‰¹å¾è‡ªé€‚åº”è®¡ç®—æƒé‡
            batch_size = x.size(0)
            x_flat = x.view(batch_size, -1)  # (batch, num_channels * feature_dim)
            alpha = self.fusion_net(x_flat).squeeze(1)  # (batch,)
            return alpha
        else:
            return 0.6
    
    def forward(self, x):
        """
        x: (batch, num_channels, feature_dim)
        Returns: (batch, num_channels, num_channels)
        """
        # 1. æ„å»ºç›¸å…³æ€§å›¾
        G_corr = self.corr_graph(x)
        
        # 2. æ„å»ºè¯­ä¹‰å›¾
        G_sem = self.semantic_graph(x)
        
        # 3. è®¡ç®—èåˆæƒé‡
        alpha = self.compute_fusion_weight(x)
        
        # 4. èåˆä¸¤ç§å›¾
        if self.fusion_mode == 'adaptive':
            # è‡ªé€‚åº”èåˆï¼ˆæ¯ä¸ªæ ·æœ¬ä¸åŒæƒé‡ï¼‰
            alpha = alpha.view(-1, 1, 1)  # (batch, 1, 1)
            G_hybrid = alpha * G_corr + (1 - alpha) * G_sem
        else:
            # å›ºå®šæˆ–å­¦ä¹ çš„å…¨å±€æƒé‡
            G_hybrid = alpha * G_corr + (1 - alpha) * G_sem
        
        return G_hybrid


class MultiScaleGCN(nn.Module):
    """å¤šå°ºåº¦å›¾å·ç§¯ç½‘ç»œ"""
    def __init__(self, in_dim, hidden_dim, num_layers=3, dropout=0.1):
        super().__init__()
        self.num_layers = num_layers
        
        self.gcn_layers = nn.ModuleList()
        for i in range(num_layers):
            input_dim = in_dim if i == 0 else hidden_dim
            self.gcn_layers.append(nn.Sequential(
                nn.Linear(input_dim, hidden_dim),
                nn.LayerNorm(hidden_dim),
                nn.ReLU(),
                nn.Dropout(dropout)
            ))
    
    def forward(self, x, adj):
        """
        x: (batch, num_channels, feature_dim)
        adj: (batch, num_channels, num_channels)
        """
        for i, gcn_layer in enumerate(self.gcn_layers):
            # å›¾å·ç§¯: x' = adj @ x
            x_agg = torch.bmm(adj, x)
            # ç‰¹å¾å˜æ¢
            x = gcn_layer(x_agg)
        
        return x


class EnhancedTemporalAttention(nn.Module):
    """å¢å¼ºç‰ˆæ—¶é—´æ³¨æ„åŠ›"""
    def __init__(self, hidden_dim, num_heads=8, dropout=0.1):
        super().__init__()
        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )
        self.norm = nn.LayerNorm(hidden_dim)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, x):
        """
        x: (batch, num_channels, hidden_dim)
        """
        # å¤šå¤´æ³¨æ„åŠ›
        attn_out, _ = self.attention(x, x, x)
        
        # æ®‹å·®è¿æ¥ + å±‚å½’ä¸€åŒ–
        x = self.norm(x + self.dropout(attn_out))
        
        return x


class DSTGV2Hybrid(nn.Module):
    """
    DSTG-V2 æ··åˆå›¾æ¨¡å‹
    
    æ ¸å¿ƒåˆ›æ–°:
    1. æ··åˆå›¾æ„å»ºï¼ˆç›¸å…³æ€§ + è¯­ä¹‰ï¼‰
    2. å¤šå°ºåº¦ GCN
    3. å¢å¼ºæ—¶é—´æ³¨æ„åŠ›
    """
    def __init__(self, num_channels=22, feature_dim=448, hidden_dim=128, 
                 output_dim=128, fusion_mode='learned', fixed_alpha=0.6):
        super().__init__()
        
        print("\n" + "="*70)
        print("ğŸš€ åˆå§‹åŒ– DSTG-V2 æ··åˆå›¾æ¨¡å‹")
        print("="*70)
        
        # æ··åˆå›¾æ„å»ºå™¨ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼ï¼‰
        self.graph_constructor = HybridGraphConstructor(
            num_channels=num_channels,
            feature_dim=feature_dim,
            hidden_dim=64,
            fusion_mode=fusion_mode,
            fixed_alpha=fixed_alpha
        )
        
        # å¤šå°ºåº¦ GCN
        self.gcn = MultiScaleGCN(
            in_dim=feature_dim,
            hidden_dim=hidden_dim,
            num_layers=3
        )
        print("âœ… å¤šå°ºåº¦GCNåˆå§‹åŒ–å®Œæˆ (3å±‚)")
        
        # å¢å¼ºç‰ˆæ—¶é—´æ³¨æ„åŠ›
        self.temporal_attention = EnhancedTemporalAttention(
            hidden_dim=hidden_dim,
            num_heads=8
        )
        print("âœ… å¢å¼ºç‰ˆæ—¶é—´æ³¨æ„åŠ›åˆå§‹åŒ–å®Œæˆ (8å¤´)")
        
        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Sequential(
            nn.Linear(hidden_dim * num_channels, output_dim),
            nn.LayerNorm(output_dim),
            nn.ReLU()
        )
        
        # è®¡ç®—å‚æ•°é‡
        total_params = sum(p.numel() for p in self.parameters())
        
        print("="*70)
        print("âœ… DSTG-V2 æ··åˆå›¾æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        print(f"   å‚æ•°é‡: {total_params:,}")
        print(f"   éšè—å±‚ç»´åº¦: {hidden_dim}")
        print(f"   GCNå±‚æ•°: 3")
        print(f"   æ³¨æ„åŠ›å¤´æ•°: 8")
        print(f"   èåˆæ¨¡å¼: {fusion_mode}")
        print("="*70 + "\n")
    
    def forward(self, x):
        """
        x: (batch, num_channels, feature_dim)
        Returns: (batch, output_dim)
        """
        batch_size, num_channels, feature_dim = x.size()
        
        # 1. æ„å»ºæ··åˆå›¾
        adj_matrix = self.graph_constructor(x)
        
        # 2. å¤šå°ºåº¦ GCN
        x_gcn = self.gcn(x, adj_matrix)
        
        # 3. æ—¶é—´æ³¨æ„åŠ›
        x_attn = self.temporal_attention(x_gcn)
        
        # 4. å…¨å±€æ± åŒ– + è¾“å‡ºæŠ•å½±
        x_flat = x_attn.view(batch_size, -1)
        output = self.output_proj(x_flat)
        
        return output
    
    def get_features(self, x):
        """
        æå–ç‰¹å¾ï¼ˆç”¨äºå¯¹æ¯”å­¦ä¹ å’ŒåŸå‹è®¡ç®—ï¼‰
        ä¸ forward ç›¸åŒ
        """
        return self.forward(x)
