"""
è‡ªé€‚åº”åŸå‹æ•°é‡é€‰æ‹©å™¨ (åŸºäºMDLåŸåˆ™)

æ ¸å¿ƒåˆ›æ–°: ä½¿ç”¨æœ€å°æè¿°é•¿åº¦(Minimum Description Length)åŸåˆ™
è‡ªåŠ¨ç¡®å®šæ¯ä¸ªæ‚£è€…çš„æœ€ä¼˜åŸå‹æ•°é‡K

ç†è®ºä¾æ®:
- Rissanen, J. (1978). "Modeling by shortest data description"
- MDLåŸåˆ™åœ¨ç»Ÿè®¡å­¦ä¸Šç­‰ä»·äºè´å¶æ–¯æ¨¡å‹é€‰æ‹©
- æ¸è¿‘ä¸€è‡´æ€§: lim_{Nâ†’âˆ} P(K* = K_true) = 1

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024-11-19
"""

import torch
import torch.nn as nn
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt


class AdaptivePrototypeSelector(nn.Module):
    """
    åŸºäºMDLåŸåˆ™çš„è‡ªé€‚åº”åŸå‹æ•°é‡é€‰æ‹©å™¨
    
    MDL(K) = Data_Cost(K) + Model_Cost(K)
    
    Data_Cost: ç”¨Kä¸ªåŸå‹æè¿°æ•°æ®çš„ä»£ä»·(é‡å»ºè¯¯å·®)
    Model_Cost: å­˜å‚¨Kä¸ªåŸå‹çš„ä»£ä»·(æ¨¡å‹å¤æ‚åº¦)
    
    æœ€ä¼˜K* = argmin_K MDL(K)
    """
    
    def __init__(self, max_K=10, min_K=1, random_state=42):
        """
        Args:
            max_K: æœ€å¤§åŸå‹æ•°é‡
            min_K: æœ€å°åŸå‹æ•°é‡
            random_state: éšæœºç§å­
        """
        super().__init__()
        self.max_K = max_K
        self.min_K = min_K
        self.random_state = random_state
    
    def compute_data_cost(self, features, prototypes):
        """
        è®¡ç®—æ•°æ®ä»£ä»·(é‡å»ºè¯¯å·®)
        
        Data_Cost = Î£_i min_k ||x_i - p_k||^2
        
        Args:
            features: (N, D) ç‰¹å¾å‘é‡
            prototypes: (K, D) åŸå‹å‘é‡
        
        Returns:
            data_cost: float, æ•°æ®é‡å»ºä»£ä»·
        """
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬åˆ°æ‰€æœ‰åŸå‹çš„è·ç¦»
        distances = torch.cdist(features, prototypes)  # (N, K)
        
        # æ¯ä¸ªæ ·æœ¬åˆ°æœ€è¿‘åŸå‹çš„è·ç¦»
        min_distances = distances.min(dim=1)[0]  # (N,)
        
        # æ•°æ®ä»£ä»· = é‡å»ºè¯¯å·®çš„å¹³æ–¹å’Œ
        data_cost = min_distances.pow(2).sum()
        
        return data_cost.item()
    
    def compute_model_cost(self, K, D, N):
        """
        è®¡ç®—æ¨¡å‹ä»£ä»·(ç¼–ç Kä¸ªåŸå‹çš„ä»£ä»·)
        
        Model_Cost = K * D * log(N)
        
        ç†è®ºä¾æ®:
        - ç¼–ç Kä¸ªDç»´åŸå‹éœ€è¦K*Dä¸ªå‚æ•°
        - æ¯ä¸ªå‚æ•°éœ€è¦log(N)æ¯”ç‰¹æ¥ç¼–ç 
        
        Args:
            K: åŸå‹æ•°é‡
            D: ç‰¹å¾ç»´åº¦
            N: æ ·æœ¬æ•°é‡
        
        Returns:
            model_cost: float, æ¨¡å‹å¤æ‚åº¦ä»£ä»·
        """
        model_cost = K * D * np.log(N)
        return model_cost
    
    def compute_mdl_score(self, features, K, prototypes):
        """
        è®¡ç®—MDLåˆ†æ•°
        
        MDL(K) = Data_Cost(K) + Model_Cost(K)
        
        Args:
            features: (N, D) ç‰¹å¾å‘é‡
            K: åŸå‹æ•°é‡
            prototypes: (K, D) åŸå‹å‘é‡
        
        Returns:
            mdl_score: float, MDLåˆ†æ•°(è¶Šå°è¶Šå¥½)
        """
        N, D = features.shape
        
        # æ•°æ®ä»£ä»·
        data_cost = self.compute_data_cost(features, prototypes)
        
        # æ¨¡å‹ä»£ä»·
        model_cost = self.compute_model_cost(K, D, N)
        
        # MDLåˆ†æ•°
        mdl_score = data_cost + model_cost
        
        return mdl_score
    
    def fit_kmeans(self, features, K):
        """
        ä½¿ç”¨K-meansèšç±»å¾—åˆ°Kä¸ªåŸå‹
        
        Args:
            features: (N, D) ç‰¹å¾å‘é‡
            K: åŸå‹æ•°é‡
        
        Returns:
            prototypes: (K, D) åŸå‹å‘é‡
        """
        # è½¬æ¢ä¸ºnumpy
        features_np = features.detach().cpu().numpy()
        
        # K-meansèšç±»
        kmeans = KMeans(
            n_clusters=K, 
            random_state=self.random_state,
            n_init=10,
            max_iter=300
        )
        kmeans.fit(features_np)
        
        # è·å–èšç±»ä¸­å¿ƒä½œä¸ºåŸå‹
        prototypes = torch.from_numpy(
            kmeans.cluster_centers_
        ).float().to(features.device)
        
        return prototypes
    
    def select_optimal_K(self, features, verbose=True):
        """
        è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜Kå€¼
        
        ç®—æ³•:
        1. å¯¹K âˆˆ [min_K, max_K]
        2. ä½¿ç”¨K-meanså¾—åˆ°Kä¸ªåŸå‹
        3. è®¡ç®—MDL(K)
        4. è¿”å›argmin_K MDL(K)
        
        Args:
            features: (N, D) ç‰¹å¾å‘é‡
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
        Returns:
            best_K: int, æœ€ä¼˜åŸå‹æ•°é‡
            mdl_scores: list, æ¯ä¸ªKå¯¹åº”çš„MDLåˆ†æ•°
            all_prototypes: dict, æ¯ä¸ªKå¯¹åº”çš„åŸå‹
        """
        N, D = features.shape
        
        if N < self.min_K:
            # æ ·æœ¬æ•°å¤ªå°‘ï¼Œç›´æ¥è¿”å›1
            if verbose:
                print(f"âš ï¸  æ ·æœ¬æ•°({N})å°äºmin_K({self.min_K})ï¼Œè¿”å›K=1")
            return 1, [0], {1: features.mean(dim=0, keepdim=True)}
        
        mdl_scores = []
        all_prototypes = {}
        
        # éå†æ‰€æœ‰å¯èƒ½çš„Kå€¼
        K_range = range(self.min_K, min(self.max_K, N) + 1)
        
        for K in K_range:
            # K-meansèšç±»
            prototypes = self.fit_kmeans(features, K)
            
            # è®¡ç®—MDLåˆ†æ•°
            mdl = self.compute_mdl_score(features, K, prototypes)
            mdl_scores.append(mdl)
            all_prototypes[K] = prototypes
            
            if verbose:
                data_cost = self.compute_data_cost(features, prototypes)
                model_cost = self.compute_model_cost(K, D, N)
                print(f"K={K}: MDL={mdl:.2f} (Data={data_cost:.2f}, Model={model_cost:.2f})")
        
        # é€‰æ‹©MDLæœ€å°çš„K
        best_idx = np.argmin(mdl_scores)
        best_K = list(K_range)[best_idx]
        
        if verbose:
            print(f"âœ… æœ€ä¼˜Kå€¼: {best_K} (MDL={mdl_scores[best_idx]:.2f})")
        
        return best_K, mdl_scores, all_prototypes
    
    def plot_mdl_curve(self, mdl_scores, best_K, save_path=None):
        """
        å¯è§†åŒ–MDLæ›²çº¿
        
        Args:
            mdl_scores: list, MDLåˆ†æ•°
            best_K: int, æœ€ä¼˜Kå€¼
            save_path: str, ä¿å­˜è·¯å¾„
        """
        K_range = range(self.min_K, self.min_K + len(mdl_scores))
        
        plt.figure(figsize=(10, 6))
        plt.plot(K_range, mdl_scores, 'b-o', linewidth=2, markersize=8)
        plt.axvline(x=best_K, color='r', linestyle='--', linewidth=2, 
                   label=f'Optimal K={best_K}')
        plt.xlabel('Number of Prototypes (K)', fontsize=14)
        plt.ylabel('MDL Score', fontsize=14)
        plt.title('MDL-based Prototype Selection', fontsize=16)
        plt.legend(fontsize=12)
        plt.grid(True, alpha=0.3)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š MDLæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")
        else:
            plt.show()
        
        plt.close()


def test_mdl_selector():
    """
    æµ‹è¯•MDLé€‰æ‹©å™¨
    """
    print("=" * 80)
    print("æµ‹è¯•MDLè‡ªé€‚åº”åŸå‹é€‰æ‹©å™¨")
    print("=" * 80)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® (3ä¸ªçœŸå®ç°‡)
    np.random.seed(42)
    torch.manual_seed(42)
    
    # ç°‡1: ä¸­å¿ƒåœ¨(0, 0)
    cluster1 = torch.randn(100, 128) * 0.5
    
    # ç°‡2: ä¸­å¿ƒåœ¨(5, 5)
    cluster2 = torch.randn(80, 128) * 0.5 + 5
    
    # ç°‡3: ä¸­å¿ƒåœ¨(-5, 5)
    cluster3 = torch.randn(70, 128) * 0.5 + torch.tensor([-5, 5] + [0]*126)
    
    # åˆå¹¶æ•°æ®
    features = torch.cat([cluster1, cluster2, cluster3], dim=0)
    
    print(f"\næ•°æ®: {features.shape[0]}ä¸ªæ ·æœ¬, {features.shape[1]}ç»´ç‰¹å¾")
    print(f"çœŸå®ç°‡æ•°: 3\n")
    
    # åˆ›å»ºé€‰æ‹©å™¨
    selector = AdaptivePrototypeSelector(max_K=10, min_K=1)
    
    # é€‰æ‹©æœ€ä¼˜K
    best_K, mdl_scores, all_prototypes = selector.select_optimal_K(
        features, verbose=True
    )
    
    print(f"\n{'='*80}")
    print(f"ç»“æœ: æœ€ä¼˜K={best_K} (çœŸå®K=3)")
    print(f"{'='*80}")
    
    # å¯è§†åŒ–MDLæ›²çº¿
    selector.plot_mdl_curve(
        mdl_scores, best_K, 
        save_path='mdl_curve_test.png'
    )
    
    return best_K, mdl_scores


if __name__ == '__main__':
    test_mdl_selector()
