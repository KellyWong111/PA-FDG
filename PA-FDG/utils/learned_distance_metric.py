"""
å­¦ä¹ çš„è·ç¦»åº¦é‡ (Mahalanobisè·ç¦»)

æ ¸å¿ƒåˆ›æ–°: å­¦ä¹ ä»»åŠ¡è‡ªé€‚åº”çš„è·ç¦»åº¦é‡,è€Œä¸æ˜¯å›ºå®šçš„æ¬§æ°è·ç¦»

ç†è®ºä¾æ®:
- Mahalanobisè·ç¦»: d_M(x,p) = âˆš((x-p)^T M (x-p))
- Mæ˜¯æ­£å®šçŸ©é˜µ,ç­‰ä»·äºåæ–¹å·®çŸ©é˜µçš„é€†
- è‡ªåŠ¨å­¦ä¹ ç‰¹å¾çš„é‡è¦æ€§å’Œç›¸å…³æ€§ç»“æ„

ä½œè€…: AI Assistant  
æ—¥æœŸ: 2024-11-19
"""

import torch
import torch.nn as nn
import numpy as np


class LearnedMahalanobisDistance(nn.Module):
    """
    å­¦ä¹ çš„Mahalanobisè·ç¦»åº¦é‡
    
    d_M(x, p) = âˆš((x-p)^T M (x-p))
    
    å…¶ä¸­Mæ˜¯å­¦ä¹ çš„æ­£å®šçŸ©é˜µ
    
    å®ç°æŠ€å·§:
    - ä½¿ç”¨Choleskyåˆ†è§£: M = L @ L^T ä¿è¯æ­£å®šæ€§
    - Læ˜¯ä¸‹ä¸‰è§’çŸ©é˜µ,å¯ä»¥ç›´æ¥å­¦ä¹ 
    """
    
    def __init__(self, feature_dim=128):
        """
        Args:
            feature_dim: ç‰¹å¾ç»´åº¦
        """
        super().__init__()
        self.feature_dim = feature_dim
        
        # å­¦ä¹ Choleskyåˆ†è§£çš„ä¸‹ä¸‰è§’çŸ©é˜µL
        # M = L @ L^T ä¿è¯Mæ­£å®š
        self.L = nn.Parameter(torch.eye(feature_dim))
    
    def get_M(self):
        """
        è·å–æ­£å®šçŸ©é˜µM
        
        M = L @ L^T
        
        Returns:
            M: (D, D) æ­£å®šçŸ©é˜µ
        """
        M = self.L @ self.L.T
        return M
    
    def mahalanobis_distance(self, x, prototype):
        """
        è®¡ç®—Mahalanobisè·ç¦»
        
        d_M(x, p) = âˆš((x-p)^T M (x-p))
        
        Args:
            x: (N, D) æˆ– (D,) æŸ¥è¯¢å‘é‡
            prototype: (D,) åŸå‹å‘é‡
        
        Returns:
            distances: (N,) æˆ– scalar
        """
        # ç¡®ä¿xæ˜¯2D
        if x.dim() == 1:
            x = x.unsqueeze(0)
            squeeze_output = True
        else:
            squeeze_output = False
        
        # è®¡ç®—å·®å€¼
        diff = x - prototype.unsqueeze(0)  # (N, D)
        
        # è·å–MçŸ©é˜µ
        M = self.get_M()  # (D, D)
        
        # è®¡ç®—Mahalanobisè·ç¦»
        # d^2 = (x-p)^T M (x-p)
        dist_squared = torch.sum(diff @ M * diff, dim=1)  # (N,)
        
        # å–å¹³æ–¹æ ¹
        distances = torch.sqrt(torch.clamp(dist_squared, min=1e-8))
        
        if squeeze_output:
            distances = distances.squeeze(0)
        
        return distances
    
    def batch_mahalanobis_distance(self, x, prototypes):
        """
        æ‰¹é‡è®¡ç®—åˆ°å¤šä¸ªåŸå‹çš„Mahalanobisè·ç¦»
        
        Args:
            x: (N, D) æŸ¥è¯¢å‘é‡
            prototypes: (K, D) åŸå‹å‘é‡
        
        Returns:
            distances: (N, K) è·ç¦»çŸ©é˜µ
        """
        N = x.shape[0]
        K = prototypes.shape[0]
        
        distances = torch.zeros(N, K, device=x.device)
        
        for k in range(K):
            distances[:, k] = self.mahalanobis_distance(x, prototypes[k])
        
        return distances
    
    def get_feature_importance(self):
        """
        è·å–ç‰¹å¾é‡è¦æ€§
        
        ä»MçŸ©é˜µçš„å¯¹è§’çº¿å…ƒç´ å¯ä»¥çœ‹å‡ºç‰¹å¾çš„é‡è¦æ€§
        
        Returns:
            importance: (D,) ç‰¹å¾é‡è¦æ€§åˆ†æ•°
        """
        M = self.get_M()
        importance = torch.diag(M)
        return importance
    
    def visualize_M_matrix(self, save_path=None):
        """
        å¯è§†åŒ–MçŸ©é˜µ
        
        Args:
            save_path: ä¿å­˜è·¯å¾„
        """
        import matplotlib.pyplot as plt
        
        M = self.get_M().detach().cpu().numpy()
        
        plt.figure(figsize=(10, 8))
        plt.imshow(M, cmap='RdBu_r', aspect='auto')
        plt.colorbar(label='Matrix Value')
        plt.title('Learned Mahalanobis Distance Matrix M', fontsize=16)
        plt.xlabel('Feature Dimension', fontsize=14)
        plt.ylabel('Feature Dimension', fontsize=14)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š MçŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}")
        else:
            plt.show()
        
        plt.close()


class DiagonalMahalanobisDistance(nn.Module):
    """
    å¯¹è§’Mahalanobisè·ç¦» (ç®€åŒ–ç‰ˆæœ¬)
    
    å‡è®¾ç‰¹å¾ä¹‹é—´ç‹¬ç«‹,Mæ˜¯å¯¹è§’çŸ©é˜µ
    
    d_M(x, p) = âˆš(Î£_i w_i (x_i - p_i)^2)
    
    å…¶ä¸­w_iæ˜¯å­¦ä¹ çš„ç‰¹å¾æƒé‡
    
    ä¼˜åŠ¿:
    - å‚æ•°æ›´å°‘ (D vs D^2)
    - è®¡ç®—æ›´å¿«
    - å¯è§£é‡Šæ€§æ›´å¼º (ç›´æ¥çœ‹å‡ºç‰¹å¾é‡è¦æ€§)
    """
    
    def __init__(self, feature_dim=128):
        """
        Args:
            feature_dim: ç‰¹å¾ç»´åº¦
        """
        super().__init__()
        self.feature_dim = feature_dim
        
        # å­¦ä¹ ç‰¹å¾æƒé‡ (å¯¹æ•°ç©ºé—´,ä¿è¯æ­£æ€§)
        self.log_weights = nn.Parameter(torch.zeros(feature_dim))
    
    def get_weights(self):
        """
        è·å–ç‰¹å¾æƒé‡
        
        Returns:
            weights: (D,) æ­£çš„ç‰¹å¾æƒé‡
        """
        weights = torch.exp(self.log_weights)
        return weights
    
    def diagonal_mahalanobis_distance(self, x, prototype):
        """
        è®¡ç®—å¯¹è§’Mahalanobisè·ç¦»
        
        d(x, p) = âˆš(Î£_i w_i (x_i - p_i)^2)
        
        Args:
            x: (N, D) æˆ– (D,) æŸ¥è¯¢å‘é‡
            prototype: (D,) åŸå‹å‘é‡
        
        Returns:
            distances: (N,) æˆ– scalar
        """
        # ç¡®ä¿xæ˜¯2D
        if x.dim() == 1:
            x = x.unsqueeze(0)
            squeeze_output = True
        else:
            squeeze_output = False
        
        # è®¡ç®—å·®å€¼
        diff = x - prototype.unsqueeze(0)  # (N, D)
        
        # è·å–æƒé‡
        weights = self.get_weights()  # (D,)
        
        # åŠ æƒå¹³æ–¹å’Œ
        weighted_squared_diff = weights * diff.pow(2)  # (N, D)
        dist_squared = weighted_squared_diff.sum(dim=1)  # (N,)
        
        # å–å¹³æ–¹æ ¹
        distances = torch.sqrt(torch.clamp(dist_squared, min=1e-8))
        
        if squeeze_output:
            distances = distances.squeeze(0)
        
        return distances
    
    def batch_diagonal_mahalanobis_distance(self, x, prototypes):
        """
        æ‰¹é‡è®¡ç®—å¯¹è§’Mahalanobisè·ç¦»
        
        Args:
            x: (N, D)
            prototypes: (K, D)
        
        Returns:
            distances: (N, K)
        """
        N = x.shape[0]
        K = prototypes.shape[0]
        
        distances = torch.zeros(N, K, device=x.device)
        
        for k in range(K):
            distances[:, k] = self.diagonal_mahalanobis_distance(
                x, prototypes[k]
            )
        
        return distances
    
    def get_feature_importance(self):
        """
        è·å–ç‰¹å¾é‡è¦æ€§ (å°±æ˜¯æƒé‡æœ¬èº«)
        
        Returns:
            importance: (D,) ç‰¹å¾é‡è¦æ€§
        """
        return self.get_weights()
    
    def visualize_feature_importance(self, save_path=None, top_k=20):
        """
        å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
        
        Args:
            save_path: ä¿å­˜è·¯å¾„
            top_k: æ˜¾ç¤ºå‰kä¸ªæœ€é‡è¦çš„ç‰¹å¾
        """
        import matplotlib.pyplot as plt
        
        importance = self.get_feature_importance().detach().cpu().numpy()
        
        # æ’åº
        sorted_indices = np.argsort(importance)[::-1]
        top_indices = sorted_indices[:top_k]
        top_importance = importance[top_indices]
        
        plt.figure(figsize=(12, 6))
        plt.bar(range(top_k), top_importance)
        plt.xlabel('Feature Index', fontsize=14)
        plt.ylabel('Importance Weight', fontsize=14)
        plt.title(f'Top {top_k} Feature Importance', fontsize=16)
        plt.xticks(range(top_k), top_indices, rotation=45)
        plt.grid(True, alpha=0.3, axis='y')
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜åˆ°: {save_path}")
        else:
            plt.show()
        
        plt.close()


def test_distance_metrics():
    """
    æµ‹è¯•è·ç¦»åº¦é‡
    """
    print("=" * 80)
    print("æµ‹è¯•å­¦ä¹ çš„è·ç¦»åº¦é‡")
    print("=" * 80)
    
    torch.manual_seed(42)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    feature_dim = 128
    x = torch.randn(100, feature_dim)
    prototypes = torch.randn(3, feature_dim)
    
    # æµ‹è¯•å®Œæ•´Mahalanobisè·ç¦»
    print("\n1. å®Œæ•´Mahalanobisè·ç¦»")
    print("-" * 80)
    mahal_metric = LearnedMahalanobisDistance(feature_dim)
    
    distances = mahal_metric.batch_mahalanobis_distance(x, prototypes)
    print(f"è·ç¦»çŸ©é˜µ: {distances.shape}")
    print(f"è·ç¦»èŒƒå›´: [{distances.min():.4f}, {distances.max():.4f}]")
    
    # å¯è§†åŒ–MçŸ©é˜µ
    mahal_metric.visualize_M_matrix('mahalanobis_M_matrix.png')
    
    # æµ‹è¯•å¯¹è§’Mahalanobisè·ç¦»
    print("\n2. å¯¹è§’Mahalanobisè·ç¦»")
    print("-" * 80)
    diag_metric = DiagonalMahalanobisDistance(feature_dim)
    
    distances_diag = diag_metric.batch_diagonal_mahalanobis_distance(
        x, prototypes
    )
    print(f"è·ç¦»çŸ©é˜µ: {distances_diag.shape}")
    print(f"è·ç¦»èŒƒå›´: [{distances_diag.min():.4f}, {distances_diag.max():.4f}]")
    
    # å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
    diag_metric.visualize_feature_importance(
        'feature_importance.png', top_k=20
    )
    
    # å¯¹æ¯”æ¬§æ°è·ç¦»
    print("\n3. å¯¹æ¯”æ¬§æ°è·ç¦»")
    print("-" * 80)
    euclidean_distances = torch.cdist(x, prototypes)
    print(f"æ¬§æ°è·ç¦»èŒƒå›´: [{euclidean_distances.min():.4f}, {euclidean_distances.max():.4f}]")
    
    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print("=" * 80)


if __name__ == '__main__':
    test_distance_metrics()
